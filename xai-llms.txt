===/docs/debugging===
#### Getting Started

# Debugging Errors

When you send a request, you would normally get a `200 OK` response from the server with the expected response body.
If there has been an error with your request, or error with our service, the API endpoint will typically return an error code with error message.

If there is an ongoing service disruption, you can visit [https://status.x.ai](https://status.x.ai) for the latest updates. The status is also available via RSS at [https://status.x.ai/feed.xml](https://status.x.ai/feed.xml).

The service status is also indicated in the navigation bar of this site.

Most of the errors will be accompanied by an error message that is self-explanatory. For typical status codes of each endpoint, visit [API Reference](api-reference) or view our [OpenAPI Document](https://docs.x.ai/openapi.json).

## Status Codes

Here is a list of potential errors and statuses arranged by status codes.

### 4XX Status Codes

| Status Code                    | Endpoints                              | Cause                                                                 | Solution                              |
|--------------------------------|----------------------------------------|-----------------------------------------------------------------------|---------------------------------------|
| 400Bad Request            | All Endpoints                          | - A `POST` method request body specified an invalid argument, or a `GET` method with dynamic route has an invalid param in the URL.- An incorrect API key is supplied. | - Please check your request body or request URL. |
| 401Unauthorized           | All Endpoints                          | - No authorization header or an invalid authorization token is provided. | - Supply an `Authorization: Bearer Token <XAI_API_KEY>` in the request header. You can get a new API key on [xAI Console](https://console.x.ai). |
| 403Forbidden              | All Endpoints                          | - Your API key/team doesn't have permission to perform the action.- Your API key/team is blocked. | - Ask your team admin for permission. |
| 404Not Found              | All Endpoints                          | - A model specified in a `POST` method request body is not found.- Trying to reach an invalid endpoint URL. (Misspelled URL) | - Check your request body and endpoint URL with our [API Reference](api-reference). |
| 405Method Not Allowed     | All Endpoints                          | - The request method is not allowed. For example, sending a `POST` request to an endpoint supporting only `GET`. | - Check your request method with our [API Reference](api-reference). |
| 415Unsupported Media Type | All Endpoints Supporting `POST` Method | - An empty request body in `POST` requests.- Not specifying `Content-Type: application/json` header. | - Add a valid request body. - Ensure `Content-Type: application/json` header is present in the request header. |
| 422Unprocessable Entity   | All Endpoints Supporting `POST` Method | - An invalid format for a field in the `POST` request body.  | - Check your request body is valid. You can find more information from [API Reference](api-reference). |
| 429Too Many Requests      | All Inference Endpoints                | - You are sending requests too frequently and reaching rate limit | - Reduce your request rate or increase your rate limit. You can find your current rate limit on [xAI Console](https://console.x.ai). |

### 2XX Error Codes

| Status Code                    | Endpoints                                   | Cause                                                                 | Solution                              |
|--------------------------------|---------------------------------------------|-----------------------------------------------------------------------|---------------------------------------|
| 202Accepted               | `/v1/chat/deferred-completion/{request_id}` | - Your deferred chat completion request is queued for processing, but the response is not available yet. | - Wait for request processing. |

## Bug Report

If you believe you have encountered a bug and would like to contribute to our development process, [email API Bug Report](mailto:support@x.ai?subject=API%20Bug%20Report) to support@x.ai with your API request and response and relevant logs.

You can also chat in the `#help` channel of our [xAI API Developer Discord](https://discord.gg/x-ai).


===/docs/faq===
#### Getting Started

# Frequently Asked Questions - General

Frequently asked questions by our customers.

For product-specific questions, visit  or .

### Does the xAI API provide access to live data?

No, the xAI API uses only the core Grok model and does not include real-time data from X posts, the internet, or current events. This differs from the Grok experience on X.com, which can leverage such data. To give Grok access to real-time or external data, please see our [Function Calling guide](guides/function-calling).

### How do I contact Sales?

For customers with bespoke needs or to request custom pricing, please fill out our [Grok for Business form](https://x.ai/grok/business). A member of our team will reach out with next steps.

### Where are your Terms of Service and Privacy Policy?

Please refer to our [Legal Resources](https://x.ai/legal) for all legal-related inquiries.

### Does xAI sell crypto tokens?

xAI is not affiliated with any cryptocurrency. We are aware of several scam websites that unlawfully use our name and logo.

### I have issues using X, can I reach out to xAI for help?

While xAI provides the Grok in X service on X.com and X apps, it does not have operational oversight of X's service. You can contact X via their [Help Center](https://help.x.com/) or message [@premium on X](https://x.com/premium).

### How do I add X account as a sign-in method or link my X subscription?

If you have an existing xAI account, **DO NOT** sign-up with X account if you want to add your X account as a sign-in method.

If you don't have an xAI account, signing up with X account will automatically link your X account subscription status with X.

If you have an xAI account without X as a sign-in method, please follow the steps outlined here: [How can I link my X account sign-in/subscription to my xAI account?](resources/faq-grok#how-can-i-link-my-x-account-sign-insubscription-to-my-xai-account)

### I signed-up to Grok / xAI API with my X account, why is xAI still asking for my email?

When you sign up with X, you will be prompted with the following:

As X does not provide the email address, you can have different emails on your X account and xAI account.

You cannot edit your account email after sign-up. Please enter your email carefully to ensure access.

### I received an email of someone logging into my xAI account

xAI will send an email to you when someone logs into your xAI account. The login location is an approximation based on your IP address, which is dependent on your network setup and ISP and might not reflect exactly where the login happened.

If you think the login is not you, please [reset your password](https://accounts.x.ai/request-reset-password) and [clear your login sessions](https://accounts.x.ai/sessions). We also recommend all users to [add a multi-factor authentication method](https://accounts.x.ai/mfa/devices).


===/docs/introduction===
#### Introduction

# What is Grok?

Grok is a family of Large Language Models (LLMs) developed by [xAI](https://x.ai).

Inspired by the Hitchhiker's Guide to the Galaxy, Grok is a maximally truth-seeking AI that provides insightful, unfiltered truths about the universe.

xAI offers an API for developers to programmatically interact with our Grok [models](models). The same models power our consumer facing services such as [Grok.com](https://grok.com), the [iOS](https://apps.apple.com/us/app/grok/id6670324846) and [Android](https://play.google.com/store/apps/details?id=ai.x.grok) apps, as well as [Grok in X experience](https://grok.x.com).

## What is the xAI API? How is it different from Grok in other services?

The xAI API is a toolkit for developers to integrate xAI's Grok models into their own applications, the xAI API provides the building blocks to create new AI experiences.

To get started building with the xAI API, please head to [The Hitchhiker's Guide to Grok](tutorial).

## xAI API vs Grok in other services

Because these are separate offerings, your purchase on X (e.g. X Premium) won't affect your service status on xAI API, and vice versa.

This documentation is intended for users using xAI API.


===/docs/overview===
#### Getting started

# Welcome

Welcome to the xAI developer docs! Our API makes it easy to harness Grok's intelligence in your projects. Grok is our flagship AI model designed to deliver truthful, insightful answers.

## Jump right in

Are you a non-developer or simply looking for our consumer services? Visit [Grok.com](https://grok.com) or download one of the [iOS](https://apps.apple.com/us/app/grok/id6670324846) or [Android](https://play.google.com/store/apps/details?id=ai.x.grok) apps. See our [Comparison Table](introduction#xai-api-vs-grok-in-other-services) for the differences.

## Questions and feedback

If you have any questions or feedback, feel free to email us at support@x.ai.

Happy Grokking! ðŸ˜Ž


===/docs/release-notes===
#### What's New?

# Release Notes

Stay up to date with the latest changes to the xAI API.

# April 2025

### Grok 3 models launch on API

Our latest flagship `Grok 3` models are now generally available via the API. For more info, see [models](models).

# March 2025

### Image Generation Model available on API

The image generation model is available on API. Visit [Image Generations](/docs/guides/image-generations) for more details on using the model.

# February 2025

### Audit Logs

Team admins can now view audit logs on [console.x.ai](https://console.x.ai).

# January 2025

### Docs Dark Mode

Released dark mode support on [docs.x.ai](https://docs.x.ai/).

### Status Page

Check service statuses across all xAI products at [status.x.ai](https://status.x.ai/).

# December 2024

### Replit & xAI

Replit Agents can now integrate with xAI! Start empowering your agents with Grok. Check out the [announcement](https://x.com/Replit/status/1874211039258333643) for more information.

### Tokenizer Playground

Understanding tokens can be hard. Check out [console.x.ai](https://console.x.ai) to get a better understanding of what counts as a token.

### Structured Outputs

We're excited to announce that Grok now supports structured outputs. Grok can now format responses in a predefined, organized format rather than free-form text.

1. Specify the desired schema

```
{
    "name": "movie_response",
    "schema": {
        "type": "object",
        "properties": {
            "title": { "type": "string" },
            "rating": { "type": "number" },
        },
        "required": [ "title", "rating" ],
        "additionalProperties": false
    },
    "strict": true
}
```

2. Get the desired data

```
{
  "title": "Star Wars",
  "rating": 8.6
}
```

Start building more reliable applications. Check out the [docs](guides/structured-outputs#structured-outputs) for more information.

### Released the new grok-2-1212 and grok-2-vision-1212 models

A month ago, we launched the public beta of our enterprise API with grok-beta and grok-vision-beta. Weâ€™re adding [grok-2-1212 and grok-2-vision-1212](https://docs.x.ai/docs/models), offering better accuracy, instruction-following, and multilingual capabilities.

# November 2024

### LangChain & xAI

Our API is now available through LangChain!

* Python Docs: http://python.langchain.com/docs/integrations/providers/xai/
* Javascript Docs: http://js.langchain.com/docs/integrations/chat/xai/

What are you going to build?

### API Public Beta Released

We are happy to announce the immediate availability of our API, which gives developers programmatic access to our Grok series of foundation models. To get started, head to [console.x.ai](https://console.x.ai/) and sign up to create an account. We are excited to see what developers build using Grok.


===/docs/tutorial===
#### Getting Started

# The Hitchhiker's Guide to Grok

Welcome! In this guide, we'll walk you through the basics of using the xAI API.

## Step 1: Create an xAI Account

Carefully select your sign-up email. We cannot change your xAI account's email once you have signed-up.
You need to sign-up with a new email address and optionally delete the original account.

First, you'll need to create an xAI account to access xAI API. Sign up for an account [here](https://accounts.x.ai/sign-up?redirect=cloud-console).

Once you've created an account, you'll need to load it with credits to start using the API.

## Step 2: Generate an API Key

Create an API key via the [API Keys Page](https://console.x.ai/team/default/api-keys) in the xAI API Console.

After generating an API key, we need to save it somewhere safe! We recommend you export it as an environment variable in your terminal or save it to a `.env` file.

```bash&#x20;(Mac)
export XAI_API_KEY="your_api_key"
```

## Step 3: Make your first request

With your xAI API key exported as an environment variable, you're ready to make your first API request.

Let's test out the API using `curl`. Paste the following directly into your terminal.

```bash
curl https://api.x.ai/v1/chat/completions \\
-H "Content-Type: application/json" \\
-H "Authorization: Bearer $XAI_API_KEY" \\
-d '{
    "messages": [
        {
            "role": "system",
            "content": "You are Grok, a highly intelligent, helpful AI assistant."
        },
        {
            "role": "user",
            "content": "What is the meaning of life, the universe, and everything?"
        }
    ],
    "model": "grok-3",
    "stream": false,
    "temperature": 0
}'
```

## Step 4: Make a request from Python or Javascript

Our API is fully compatible with the OpenAI and Anthropic SDKs. For example, we can make the same request from Python or Javascript like so:

```python
# In your terminal, first run:
# pip install openai

import os
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

completion = client.chat.completions.create(
    model="grok-3",
    messages=[
        {
            "role": "system",
            "content": "You are Grok, a highly intelligent, helpful AI assistant."
        },
        {
            "role": "user",
            "content": "What is the meaning of life, the universe, and everything?"
        },
    ],
)

print(completion.choices[0].message.content)
```

```javascript
// In your terminal, first run:
// npm install openai

import OpenAI from "openai";

const client = new OpenAI({
    apiKey: "your_api_key",
    baseURL: "https://api.x.ai/v1",
});

const completion = await client.chat.completions.create({
    model: "grok-3",
    messages: [
        {
            role: "system",
            content:
                "You are Grok, a highly intelligent, helpful AI assistant.",
        },
        {
            role: "user",
            content:
                "What is the meaning of life, the universe, and everything?",
        },
    ],
});

console.log(completion.choices[0].message.content);
```

Certain models (such as `grok-3`, `grok-3-mini`, and `grok-2-vision-1212`) also support [Structured Outputs](guides/structured-outputs), which allows you to enforce a schema for the LLM output.

For an in-depth guide about using Grok for text responses, check out our [Chat Guide](guides/chat).

## Step 5: Use Grok to analyze images

Certain grok models can accept both text AND images as an input. For example:

```python
import os
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
image_url = "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png"

client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": image_url,
                    "detail": "high",
                },
            },
            {
                "type": "text",
                "text": "What's in this image?",
            },
        ],
    },
]

completion = client.chat.completions.create(
    model="grok-2-vision-latest",
    messages=messages,
    temperature=0.01,
)
print(completion.choices[0].message.content)
```

```javascript
import OpenAI from "openai";
        
const client = new OpenAI({
    apiKey: process.env.XAI_API_KEY,
    baseURL: "https://api.x.ai/v1",
});

const image_url =
    "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png";

const completion = await client.chat.completions.create({
    model: "grok-2-vision-latest",
    messages: [
        {
            role: "user",
            content: [
                {
                    type: "image_url",
                    image_url: {
                        url: image_url,
                        detail: "high",
                    },
                },
                {
                    type: "text",
                    text: "What's in this image?",
                },
            ],
        },
    ],
});

console.log(completion.choices[0].message.content);
```

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
              "url": "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png",
              "detail": "high"
            }
          },
          {
            "type": "text",
            "text": "Describe this image"
          }
        ]
      }
    ],
    "model": "grok-2-vision-latest",
    "stream": false,
    "temperature": 0
  }'
```

And voila! Grok will tell you exactly what's in the image:

> This image is a photograph of a region in space, specifically a part of the Carina Nebula, captured by the James Webb Space Telescope. It showcases a stunning view of interstellar gas and dust, illuminated by young, hot stars. The bright points of light are stars, and the colorful clouds are composed of various gases and dust particles. The image highlights the intricate details and beauty of star formation within a nebula.

To learn how to use Grok vision for more advanced use cases, check out our [Image Understanding Guide](guides/image-understanding).

## Monitoring usage

As you use your API key, you will be charged for the number of tokens used. For an overview, you can monitor your usage on the [xAI Console Usage Page](https://console.x.ai/team/default/usage).

If you want a more granular, per request usage tracking, the API response includes a usage object that provides detail on prompt (input) and completion (output) token usage.

```json
"usage": {
  "prompt_tokens": 41,
  "completion_tokens": 87,
  "total_tokens": 128,
  "prompt_tokens_details": {
    "text_tokens": 41,
    "audio_tokens": 0,
    "image_tokens": 0,
    "cached_tokens": 0
  }
}
```

If you send requests too frequently or with long prompts, you might run into rate limits and get an error response. For more information, read [Consumption and Rate Limits](consumption-and-rate-limits).

## Next steps

Now you have learned the basics of making an inference on xAI API. Check out [Models](models) page to start building with one of our latest models.


===/docs/api-reference===
# REST API

The xAI Enterprise API is a robust, high-performance RESTful interface designed for seamless integration into existing systems.
It offers advanced AI capabilities with full compatibility with the OpenAI REST API.

The base for all routes is at `https://api.x.ai`. For all routes, you have to authenticate with the header `Authorization: Bearer <your xAI API key>`.

***

## Chat completions

## POST /v1/chat/completions

API endpoint for POST requests to /v1/chat/completions.

```
Method: POST
Path: /v1/chat/completions
```

***

## Messages (Anthropic compatible)

## POST /v1/messages

API endpoint for POST requests to /v1/messages.

```
Method: POST
Path: /v1/messages
```

***

## Image generations

## POST /v1/images/generations

API endpoint for POST requests to /v1/images/generations.

```
Method: POST
Path: /v1/images/generations
```

***

## API key

## GET /v1/api-key

API endpoint for GET requests to /v1/api-key.

```
Method: GET
Path: /v1/api-key
```

***

## List models

## GET /v1/models

API endpoint for GET requests to /v1/models.

```
Method: GET
Path: /v1/models
```

***

## Get model

## GET /v1/models/\{model\_id}

API endpoint for GET requests to /v1/models/\{model\_id}.

```
Method: GET
Path: /v1/models/{model_id}
```

***

## List language models

## GET /v1/language-models

API endpoint for GET requests to /v1/language-models.

```
Method: GET
Path: /v1/language-models
```

***

## Get language model

## GET /v1/language-models/\{model\_id}

API endpoint for GET requests to /v1/language-models/\{model\_id}.

```
Method: GET
Path: /v1/language-models/{model_id}
```

***

## List image generation models

## GET /v1/image-generation-models

API endpoint for GET requests to /v1/image-generation-models.

```
Method: GET
Path: /v1/image-generation-models
```

***

## Get image generation model

## GET /v1/image-generation-models/\{model\_id}

API endpoint for GET requests to /v1/image-generation-models/\{model\_id}.

```
Method: GET
Path: /v1/image-generation-models/{model_id}
```

***

## Tokenize text

## POST /v1/tokenize-text

API endpoint for POST requests to /v1/tokenize-text.

```
Method: POST
Path: /v1/tokenize-text
```

***

## Get deferred chat completions

## GET /v1/chat/deferred-completion/\{request\_id}

API endpoint for GET requests to /v1/chat/deferred-completion/\{request\_id}.

```
Method: GET
Path: /v1/chat/deferred-completion/{request_id}
```

***

## Completions (legacy)

## POST /v1/completions

API endpoint for POST requests to /v1/completions.

```
Method: POST
Path: /v1/completions
```

***

## Completions (Anthropic compatible - legacy)

## POST /v1/complete

API endpoint for POST requests to /v1/complete.

```
Method: POST
Path: /v1/complete
```


===/docs/guides/async===
#### Guides

# Asynchronous Requests

When working with the xAI API, you may need to process hundreds or even thousands of requests. Sending these requests sequentially can be extremely time-consuming.

To improve efficiency, you can use `AsyncOpenAI` from the `openai` SDK, which allows you to send multiple requests concurrently. The example below is a Python script demonstrating how to use `AsyncOpenAI` to batch and process requests asynchronously, significantly reducing the overall execution time:

The xAI API does not currently offer a batch API.

## Rate Limits

Adjust the `max_concurrent` param to control the maximum number of parallel requests.

You are unable to concurrently run your requests beyond the rate limits shown in the API console.

```python
import asyncio
import os
from asyncio import Semaphore
from typing import List

from openai import AsyncOpenAI

client = AsyncOpenAI(
    api_key=os.getenv("XAI_API_KEY"),
    base_url="https://api.x.ai/v1"
)

async def send_request(sem: Semaphore, request: str) -> dict:
    """Send a single request to xAI with semaphore control."""
    # The 'async with sem' ensures only a limited number of requests run at once
    async with sem:
        return await client.chat.completions.create(
            model="grok-3-latest",
            messages=[{"role": "user", "content": request}]
        )

async def process_requests(requests: List[str], max_concurrent: int = 2) -> List[dict]:
    """Process multiple requests with controlled concurrency."""
    # Create a semaphore that limits how many requests can run at the same time
    # Think of it like having only 2 "passes" to make requests simultaneously
    sem = Semaphore(max_concurrent)
    
    # Create a list of tasks (requests) that will run using the semaphore
    tasks = [send_request(sem, request) for request in requests]
    
    # asyncio.gather runs all tasks in parallel but respects the semaphore limit
    # It waits for all tasks to complete and returns their results
    return await asyncio.gather(*tasks)

async def main() -> None:
    """Main function to handle requests and display responses."""
    requests = [
        "Tell me a joke",
        "Write a funny haiku",
        "Generate a funny X post",
        "Say something unhinged"
    ]

    # This starts processing all asynchronously, but only 2 at a time
    # Instead of waiting for each request to finish before starting the next,
    # we can have 2 requests running at once, making it faster overall
    responses = await process_requests(requests)
    
    # Print each response in order
    for i, response in enumerate(responses):
        print(f"# Response {i}:")
        print(response.choices[0].message.content)

if __name__ == "__main__":
    asyncio.run(main())
```


===/docs/guides/chat===
#### Guides

# Chat

Text in, text out. Chat is the most popular feature on the xAI API, and can be used for anything from summarizing articles, generating creative writing, answering questions, providing customer support, to assisting with coding tasks.

## Prerequisites

* xAI Account: You need an xAI account to access the API.
* API Key: Ensure that your API key has access to the chat endpoint and the chat model is enabled.

If you don't have these and are unsure of how to create one, follow [the Hitchhiker's Guide to Grok](../tutorial).

You can create an API key on the [xAI Console API Keys Page](https://console.x.ai/team/default/api-keys).

Set your API key in your environment:

```bash
export XAI_API_KEY="your_api_key"
```

## A Basic Chat Completions Example

You can also stream the response, which is covered in [Streaming Response](streaming-response).

The user sends a request to the xAI API endpoint. The API processes this and returns a complete response.

```python
import os
from openai import OpenAI

client = OpenAI(
    api_key="<YOUR_XAI_API_KEY_HERE>",
    base_url="https://api.x.ai/v1",
)

completion = client.chat.completions.create(
    model="grok-3-latest",
    messages=[
        {"role": "system", "content": "You are a PhD-level mathematician."},
        {"role": "user", "content": "What is 2 + 2?"},
    ],
)

print(completion.choices[0].message)
```

```javascript
import OpenAI from "openai";

const client = new OpenAI({
    apiKey: "<api key>",
    baseURL: "https://api.x.ai/v1",
});

const completion = await client.chat.completions.create({
    model: "grok-3-latest",
    messages: [
        {
            role: "system",
            content: "You are Grok, a chatbot inspired by the Hitchhiker's Guide to the Galaxy."
        },
        {
            role: "user",
            content: "What is the meaning of life, the universe, and everything?"
        },
    ],
});
console.log(completion.choices[0].message);
```

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
        "messages": [
          {
            "role": "system",
            "content": "You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy."
          },
          {
            "role": "user",
            "content": "What is the meaning of life, the universe, and everything?"
          }
        ],
        "model": "grok-3-latest",
        "stream": false,
        "temperature": 0
      }'
```

Response:

```python
ChatCompletionMessage(
    content='2 + 2 equals 4.',
    refusal=None,
    role='assistant',
    audio=None,
    function_call=None,
    tool_calls=None
)
```

```javascript
{
  role: 'assistant',
  content: \`Ah, the ultimate question! According to Douglas Adams' "The Hitchhiker's Guide to the Galaxy," the answer to the ultimate question of life, the universe, and everything is **42**. However, the guide also notes that the actual question to which this is the answer is still unknown. Isn't that delightfully perplexing? Now, if you'll excuse me, I'll just go ponder the intricacies of existence.\`
  refusal: null
}
```

```bash
{
  "id": "0daf962f-a275-4a3c-839a-047854645532",
  "object": "chat.completion",
  "created": 1739301120,
  "model": "grok-3-latest",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The meaning of life, the universe, and everything is a question that has puzzled philosophers, scientists, and hitchhikers alike. According to the Hitchhiker's Guide to the Galaxy, the answer to this ultimate question is simply \"42\". However, the exact nature of the question itself remains unknown. So, while we may have the answer, the true meaning behind it is still up for debate. In the meantime, perhaps we should all just enjoy the journey and have a good laugh along the way!",
        "refusal": null
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 41,
    "completion_tokens": 104,
    "total_tokens": 145,
    "prompt_tokens_details": {
      "text_tokens": 41,
      "audio_tokens": 0,
      "image_tokens": 0,
      "cached_tokens": 0
    }
  },
  "system_fingerprint": "fp_84ff176447"
}
```

## Conversations

The xAI API is stateless and does not process new request with the context of your previous request history.

However, you can provide previous chat generation prompts and results to a new chat generation request to let the model process your new request with the context in mind.

An example message:

```json
{
  "role": "system",
  "content": [{ "type": "text", "text": "You are a helpful and funny assistant."}]
}
{
  "role": "user",
  "content": [{ "type": "text", "text": "Why don't eggs tell jokes?" }]
},
{
  "role": "assistant",
  "content": [{ "type": "text", "text": "They'd crack up!" }]
},
{
  "role": "user",
  "content": [{"type": "text", "text": "Can you explain the joke?"}],
}
```

By specifying roles, you can change how the the model ingest the content.
The `system` role content should define, in an instructive tone, the way the model should respond to user request.
The `user` role content is usually used for user request or data sent to the model.
The `assistant` role content is usually either in the model's response, or when sent within the prompt, indicating the model's response as part of conversation history.

This strategy to send `assistant` role content can be used within function calling, in which the model response will invoke a tool call, the user's program responds to the tool call and continues the conversation by appending tool call result to the message. For more details, check out our guide on [Function Calling](/docs/guides/function-calling).

## Message role order flexibility

Unlike some models from other providers, one of the unique aspects of xAI API is its flexibility with message roles:

* No Order Limitation: You can mix `system`, `user`, or `assistant` roles in any sequence for your conversation context.

**Example 1 - Multiple System Messages:**

```json
[
{"role": "system", "content": "..."},
{"role": "system", "content": "..."},
{"role": "user", "content": "..."},
{"role": "user", "content": "..."}
]
```

The model takes multiple system

**Example 2 - User Messages First:**

```json
{"role": "user", "content": "..."},
{"role": "user", "content": "..."},
{"role": "system", "content": "..."}
```


===/docs/guides/deferred-chat-completions===
#### Guides

# Deferred Chat Completions

Deferred Chat Completions are currently available only via REST requests, not through any SDKs.

Deferred Chat Completions allow you to create a chat completion, get a `response_id`, and retrieve the response at a later time. The result would be available to be requested exactly once within 24 hours, after which it would be discarded.

After sending the request to the xAI API, the chat completion result will be available at `https://api.x.ai/v1/chat/deferred-completion/{request_id}`. The response body will contain `{'request_id': 'f15c114e-f47d-40ca-8d5c-8c23d656eeb6'}`, and the `request_id` value can be inserted into the `deferred-completion` endpoint path. Then, we send this GET request to retrieve the deferred completion result.

When the completion result is not ready, the request will return `202 Accepted` with an empty response body.

## Example

An example code is provided below, where we retry retrieving the result until it have been processed:

```python
import json
import os
import requests

from tenacity import retry, wait_exponential

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {os.getenv('XAI_API_KEY')}"
}

payload = {
    "messages": [
        {"role": "system", "content": "You are Zaphod Beeblebrox."},
        {"role": "user", "content": "126/3=?"}
    ],
    "model": "grok-3-latest",
    "deferred": True
}

response = requests.post(
    "https://api.x.ai/v1/chat/completions",
    headers=headers,
    json=payload
)
request_id = response.json()["request_id"]
print(f"Request ID: {request_id}")

@retry(wait=wait_exponential(multiplier=1, min=1, max=60),)
def get_deferred_completion():
    response = requests.get(f"https://api.x.ai/v1/chat/deferred-completion/{request_id}", headers=headers)
    if response.status_code == 200:
        return response.json()
    elif response.status_code == 202:
        raise Exception("Response not ready yet")
    else:
        raise Exception(f"{response.status_code} Error: {response.text}")

completion_data = get_deferred_completion()
print(json.dumps(completion_data, indent=4))
```

```javascript
const axios = require('axios');
const retry = require('retry');

const headers = {
  'Content-Type': 'application/json',
  'Authorization': \`Bearer \${process.env.XAI_API_KEY}\`
};

const payload = {
  messages: [
    { role: 'system', content: 'You are Zaphod Beeblebrox.' },
    { role: 'user', content: '126/3=?' }
  ],
  model: 'grok-3-latest',
  deferred: true
};

async function main() {
  const requestId = (await axios.post('https://api.x.ai/v1/chat/completions', payload, { headers })).data.request_id;
  console.log(\`Request ID: \${requestId}\`);

  const operation = retry.operation({
    minTimeout: 1000,
    maxTimeout: 60000,
    factor: 2
  });

  const completion = await new Promise((resolve, reject) => {
    operation.attempt(async () => {
      const res = await axios.get(\`https://api.x.ai/v1/chat/deferred-completion/\${requestId}\`, { headers });
      if (res.status === 200) resolve(res.data);
      else if (res.status === 202) operation.retry(new Error('Not ready'));
      else reject(new Error(\`\${res.status}: \${res.statusText}\`));
    });
  });

  console.log(JSON.stringify(completion, null, 4));
}

main().catch(console.error);
```

```bash
RESPONSE=$(curl -s https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
        "messages": [
            {"role": "system", "content": "You are Zaphod Beeblebrox."},
            {"role": "user", "content": "126/3=?"}
        ],
        "model": "grok-3-latest",
        "deferred": true
      }')

REQUEST_ID=$(echo "$RESPONSE" | jq -r '.request_id')
echo "Request ID: $REQUEST_ID"

sleep 10

curl -s https://api.x.ai/v1/chat/deferred-completion/$REQUEST_ID \\
  -H "Authorization: Bearer $XAI_API_KEY"
```

The response body will be the same as what you would expect with non-deferred chat completions:

```json
{
    "id": "c0161816-8b53-4c28-bd2b-3877c6edb800",
    "object": "chat.completion",
    "created": 3141592653,
    "model": "grok-3",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "Hey, don't ask me about math, I'm Zaphod Beeblebrox, not a calculator! But if you really need to know, it's 42, isn't it? Everything's 42!",
                "refusal": null
            },
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 27,
        "completion_tokens": 48,
        "reasoning_tokens": 0,
        "total_tokens": 75,
        "prompt_tokens_details": {
            "text_tokens": 27,
            "audio_tokens": 0,
            "image_tokens": 0,
            "cached_tokens": 0
        }
    },
    "system_fingerprint": "fp_fe9e7ef66e"
}
```

For more details, refer to [Chat completions](../api-reference#chat-completions) and [Get deferred chat completions](../api-reference#get-deferred-chat-completions) in our REST API Reference.


===/docs/guides/fingerprint===
#### Guides

# Fingerprint

For each request to the xAI API, the response body will include a unique `system_fingerprint` value. This fingerprint serves as an identifier for the current state of the backend system's configuration.

Example:

```bash
curl https://api.x.ai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $XAI_API_KEY" \
  -d '{
        "messages": [
          {
            "role": "system",
            "content": "You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy."
          },
          {
            "role": "user",
            "content": "What is the meaning of life, the universe, and everything?"
          }
        ],
        "model": "grok-3-latest",
        "stream": false,
        "temperature": 0
      }'
```

Response:

```json
{..., "system_fingerprint":"fp_6ca29cf396"}
```

You can automate your system to keep track of the `system_fingerprint` along with token consumption and other metrics.

## Usage of fingerprint

* **Monitoring System Changes:** The system fingerprint acts as a version control for the backend configuration. If any part of the backend systemâ€”such as model parameters, server settings, or even the underlying infrastructureâ€”changes, the fingerprint will also change. This allows developers to track when and how the system has evolved over time. This is crucial for debugging, performance optimization, and ensuring consistency in API responses.
* **Security and Integrity:** The fingerprint can be used to ensure the integrity of the response. If a response's fingerprint matches the expected one based on a recent system configuration, it helps in verifying that the data hasn't been tampered with during transmission or that the service hasn't been compromised. **The fingerprint will change over time and it is expected.**
* **Compliance and Auditing:** For regulated environments, this fingerprint can serve as part of an audit trail, showing when specific configurations were in use for compliance purposes.


===/docs/guides/function-calling===
#### Guides

# Function calling

Connect the xAI models to external tools and systems to build AI assistants and various integrations.

## Introduction

Function calling enables language models to use external tools, which can intimately connect models to digital and physical worlds.

This is a powerful capability that can be used to enable a wide range of use cases.

* Calling public APIs for actions ranging from looking up football game results to getting real-time satellite positioning data
* Analyzing internal databases
* Browsing web pages
* Executing code
* Interacting with the physical world (e.g. booking a flight ticket, opening your tesla car door, controlling robot arms)

## Walkthrough

The request/response flow for function calling can be demonstrated in the following illustration.

You can think of it as the LLM initiating [RPCs (Remote Procedure Calls)](https://en.wikipedia.org/wiki/Remote_procedure_call) to user system. From the LLM's perspective, the "2. Response" is an RPC request from LLM to user system, and the "3. Request" is an RPC response with information that LLM needs.

One simple example of a local computer/server, where the computer/server determines if the response from Grok contains a `tool_call`, and calls the locally-defined functions to perform user-defined actions:

The whole process looks like this in pseudocode:

```pseudocode
// ... Define tool calls and their names

messages = []

/* Step 1: Send a new user request */

messages += {<new user request message>}
response = send_request_to_grok(message)

messages += response.choices[0].message  // Append assistant response

while (true) {
    /* Step 2: Run tool call and add tool call result to messages */ 
    if (response contains tool_call) {
        // Grok asks for tool call

        for (tool in tool_calls) {
            tool_call_result = tool(arguments provided in response) // Perform tool call
            messages += tool_call_result  // Add result to message
        }
    }

    read(user_request)

    if (user_request) {
        messages += {<new user request message>}
    }

    /* Step 3: Send request with tool call result to Grok*/
    response = send_request_to_grok(message)

    print(response)
}

```

We will demonstrate the function calling in the following Python script. First, let's create an API client:

```python
import os
import json
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")

client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)
```

### Preparation - Define tool functions and function mapping

Define tool functions as callback functions to be called when model requests them in response.

Normally, these functions would either retrieve data from a database, or call another API endpoint, or perform some actions.
For demonstration purposes, we hardcode to return 59Â° Fahrenheit/15Â° Celsius as the temperature, and 15,000 feet as the cloud ceiling.

The parameters definition will be sent in the initial request to Grok, so Grok knows what tools and parameters are available to be called.

To reduce human error, you can define the tools partially using Pydantic.

Function definition using Pydantic:

```python
from pydantic import BaseModel, Field
from typing import Literal

# Defining functions and function arguments
class TemperatureRequest(BaseModel):
    location: str = Field(description="The city and state, e.g. San Francisco, CA")
    unit: Literal["celsius", "fahrenheit"] = Field(
        "fahrenheit", description="Temperature unit"
    )

class CeilingRequest(BaseModel):
    location: str = Field(description="The city and state, e.g. San Francisco, CA")

def get_current_temperature(**kwargs):
    request = TemperatureRequest(**kwargs)
    temperature: int
    if request.unit.lower() == "fahrenheit":
        temperature = 59
    elif request.unit.lower() == "celsius":
        temperature = 15
    else:
        raise ValueError("unit must be one of fahrenheit or celsius")
    return {
        "location": request.location,
        "temperature": temperature,
        "unit": request.unit.lower(),
    }

def get_current_ceiling(**kwargs):
    request = CeilingRequest(**kwargs)
    return {
        "location": request.location,
        "ceiling": 15000,
        "ceiling_type": "broken",
        "unit": "ft",
    }


# Generate the JSON schema
get_current_temperature_schema = TemperatureRequest.model_json_schema()
get_current_ceiling_schema = CeilingRequest.model_json_schema()

# Definition of parameters with Pydantic JSON schema
tools_definition = [
    {
        "type": "function",
        "function": {
            "name": "get_current_temperature",
            "description": "Get the current temperature in a given location",
            "parameters": get_current_temperature_schema,
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_current_ceiling",
            "description": "Get the current cloud ceiling in a given location",
            "parameters": get_current_ceiling_schema,
        },
    },
]
```

Function definition using raw dictionary:

```python
# Defining functions
def get_current_temperature(location: str, unit: str = "fahrenheit"):
    temperature: int
    if unit.lower() == "fahrenheit":
        temperature = 59
    elif unit.lower() == "celsius":
        temperature = 15
    else:
        raise ValueError("unit must be one of fahrenheit or celsius")
    return {"location": location, "temperature": temperature, "unit": unit}


def get_current_ceiling(location: str):
    return {
        "location": location,
        "ceiling": 15000,
        "ceiling_type": "broken",
        "unit": "ft",
    }

tools_map = {
    "get_current_temperature": get_current_temperature,
    "get_current_ceiling": get_current_ceiling,
}

# Raw dictionary definition of parameters
tools_definition = [
    {
        "type": "function",
        "function": {
            "name": "get_current_temperature",
            "description": "Get the current temperature in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "default": "fahrenheit"
                    }
                },
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_current_ceiling",
            "description": "Get the current cloud ceiling in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                    }
                },
                "required": ["location"]
            }
        }
    }
]
```

Create a string -> function mapping, so we can call the function when model sends it's name. e.g.

```python
tools_map = {
    "get_current_temperature": get_current_temperature,
    "get_current_ceiling": get_current_ceiling,
}
```

### 1. Send initial message

With all the functions defined, it's time to send our API request to Grok!

Now before we send it over, let's look at how the generic request body for a new task looks like.

Here we assume a previous tool call has Note how the tool call is referenced three times:

* By `id` and `name` in "Mesage History" assistant's first response
* By `tool_call_id` in "Message History" tool's content
* In the `tools` field of the request body

Now we compose the request messages in the request body and send it over to Grok. Grok should return a response that asks us for a tool call.

```python
messages = [{"role": "user", "content": "What's the temperature like in San Francisco?"}]
response = client.chat.completions.create(
    model="grok-3-latest",
    messages=messages,
    tools=tools_definition,  # The dictionary of our functions and their parameters
    tool_choice="auto",
)

# You can inspect the response which contains a tool call
print(response.choices[0].message)
```

### 2. Run tool functions if Grok askes tool call and append function returns to message

We retrieve the tool function names and arguments that Grok wants to call, run the functions, and add the result to messages.

At this point, you can choose to **only respond to tool call with results** or **add a new user message request**.

The `tool` message would contain the following: `{ "role": "tool", "content": <json string of tool function's returned object>, "tool_call_id": <tool_call.id included in the tool call response by Grok>}`

The request body that we try to assemble and send back to Grok. Note it looks slightly different from the new task request body:

The corresponding code to append messages:

```python
# Append assistant message including tool calls to messages
messages.append(response.choices[0].message)

# Check if there is any tool calls in response body
# You can also wrap this in a function to make the code cleaner

if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:

        # Get the tool function name and arguments Grok wants to call
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)

        # Call one of the tool function defined earlier with arguments
        result = tools_map[function_name](**function_args)

        # Append the result from tool function call to the chat message history,
        # with "role": "tool"
        messages.append(
            {
                "role": "tool",
                "content": json.dumps(result),
                "tool_call_id": tool_call.id  # tool_call.id supplied in Grok's response
            }
        )
```

### 3. Send the tool function returns back to the model to get the response

```python
response = client.chat.completions.create(
    model="grok-3-latest",
    messages=messages,
    tools=tools_definition,
    tool_choice="auto"
)

print(response.choices[0].message.content)
```

### 4. (Optional) Continue the conversation

You can continue the conversation following [Step 2](#2-run-tool-functions-if-grok-askes-tool-call-and-append-function-returns-to-message). Otherwise you can terminate.

## Function calling modes

By default, the model will automatically decide whether a function call is necessary and select which functions to call, as determined by theÂ `tool_choice: "auto"`Â setting.

We offer three ways to customize the default behavior:

1. To force the model to always call one or more functions, you can setÂ `tool_choice: "required"`. The model will then always call function. Note this could force the model to hallucinate parameters.
2. To force the model to call a specific function, you can setÂ `tool_choice: {"type": "function", "function": {"name": "my_function"}}`.
3. To disable function calling and force the model to only generate a user-facing message, you can either provide no tools, or setÂ `tool_choice: "none"`.


===/docs/guides/image-generations===
#### Guides

# Image Generations

Some of the models can provide image generation capabilities. You can provide some descriptions of the image you would like to generate, and let the model generate one or multiple pictures in the output.

If you're used to interacting with the chat/image-understanding models, the image generation is a bit different from them.
You only need to send a prompt text in the request, instead of a list of messages with system/user/assistant roles.
When you sent the prompt for image generation, your prompt will be revised by a chat model, and then sent to the image generation model.

## Parameters

* `n`: Number of image(s) to generate (1-10, default to 1)
* `response_format`: `"url"` or `"b64_json"`. If `"url"` is specified, the response will return a url to the image(s) in `data[index].url`; if "b64\_json" is specified, the response will return the image(s) in base64 encoded format in `data[index].b64_json`.

> Note: `quality`, `size` or `style` are not supported by xAI API at the moment.

## Generate image

The image generation is offered at a different endpoint `https://api.x.ai/v1/images/generations` from the chat and image-understanding models that share `https://api.x.ai/v1/chat/completions`.
The endpoint is **compatible with OpenAI SDK** (but **not with Anthropic SDK**), so you can keep using the same `base_url` of `https://api.x.ai/v1`.

You can set `"model": "grok-2-image"` in the request body to use the model. The generated image will be in `jpg` format.

```python
import os

from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(base_url="https://api.x.ai/v1", api_key=XAI_API_KEY)

response = client.images.generate(
  model="grok-2-image",
  prompt="A cat in a tree"
)

print(response.data[0].url)
```

```javascript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: "<api key>",
  baseURL: "https://api.x.ai/v1",
});

const response = await openai.images.generate({
  model: "grok-2-image",
  prompt: "A cat in a tree",
});
console.log(response.data[0].url);
```

```bash
curl -X 'POST' https://api.x.ai/v1/images/generations \\
-H 'accept: application/json' \\
-H 'Authorization: Bearer <API_KEY>' \\
-H 'Content-Type: application/json' \\
-d '{
-d '{
  "model": "grok-2-image",
  "prompt": "A cat in a tree"
}'
```

The Python and JavaScript examples will print out url of the image on xAI managed storage.

This is an example image generated from the above prompt:

### Base 64 JSON Output

Instead of getting an image url by default, you can choose to get a base64 encoded image instead.
To do so, you need to specify the `response_format` parameter to `"b64_json"`.

```python
import os

from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(base_url="https://api.x.ai/v1", api_key=XAI_API_KEY)

response = client.images.generate(
  model="grok-2-image",
  prompt="A cat in a tree",
  response_format="b64_json"
)

print(response.data[0].b64_json)
```

```javascript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: "<api key>",
  baseURL: "https://api.x.ai/v1",
});

const response = await openai.images.generate({
  model: "grok-2-image",
  prompt: "A cat in a tree",
  response_format: "b64_json"
});
console.log(response.data[0].b64_json);
```

```bash
curl -X 'POST' https://api.x.ai/v1/images/generations \\
-H 'accept: application/json' \\
-H 'Authorization: Bearer <API_KEY>' \\
-H 'Content-Type: application/json' \\
-d '{
  "model": "grok-2-image",
  "prompt": "A cat in a tree",
  "response_format": "b64_json"
}'
```

You will get a `b64_json` field instead of `url` in the response image object.

### Generating multiple images

You can generate up to 10 images in one request by adding a parameter `n` in your request body. For example, to generate four images:

```python
import os

from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(base_url="https://api.x.ai/v1", api_key=XAI_API_KEY)

response = client.images.generate(
  model="grok-2-image",
  prompt="A cat in a tree"
  n=4
)
for image in response.data:
  print(image.url)
```

```javascript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: "<api key>",
  baseURL: "https://api.x.ai/v1",
});

const response = await openai.images.generate({
  model: "grok-2-image",
  prompt: "A cat in a tree",
  n: 4
});
response.data.forEach((image) => {
  console.log(image.url);
});
```

```bash
curl -X 'POST' https://api.x.ai/v1/images/generations \\
-H 'accept: application/json' \\
-H 'Authorization: Bearer <API_KEY>' \\
-H 'Content-Type: application/json' \\
-d '{
  "model": "grok-2-image",
  "prompt": "A cat in a tree",
  "n": 4
}'
```

## Revised prompt

If you inspect the response object, you can see something similar to this:

```json
{
    "data": [
        {
            "b64_json": "data:image/png;base64,...",
            "revised_prompt": "..."
        }
    ]
}
```

Before sending the prompt to the image generation model, the prompt will be revised by a chat model. The revised prompt from chat model will be used by image generation model to create the image, and returned in `revised_prompt` to the user.

To see the revised prompt with OpenAI SDK:

```python
# ... Steps to make image generation request

print(response.data[0].revised_prompt)
```

```javascript
// ... Steps to make image generation request

console.log(response.data[0].revised_prompt);
```

For example:
| Input/Output                        | Example  |
|------------------------------------ | -------- |
| prompt (in request body)            | A cat in a tree |
| revised\_prompt (in response body)   | 3D render of a gray cat with green eyes perched on a thick branch of a leafy tree, set in a suburban backyard during the day. The cat's fur is slightly ruffled by a gentle breeze, and it is looking directly at the viewer. The background features a sunny sky with a few clouds and other trees, creating a natural and serene environment. The scene is focused on the cat, with no distracting foreground elements, ensuring the cat remains the central subject of the image. |


===/docs/guides/image-understanding===
#### Guides

# Image Understanding

The vision model can receive both text and image inputs. You can pass images into the model in one of two ways: base64 encoded strings or web URLs.

Under the hood, image understanding shares the same API route and the same message body schema consisted of `system`/`user`/`assistant` messages. The difference is having image in the message content body instead of text.

As the knowledge in this guide is built upon understanding of the chat capability. It is suggested that you familiarize yourself with the [chat](chat) capability before following this guide.

## Prerequisites

* xAI Account: You need an xAI account to access the API.
* API Key: Ensure that your API key has access to the vision endpoint and a model supporting image input is enabled.

If you don't have these and are unsure of how to create one, follow [the Hitchhiker's Guide to Grok](../tutorial).

Set your API key in your environment:

```bash
export XAI_API_KEY="your_api_key"
```

## Reminder on image understanding model general limitations

It might be easier to run into model limit with these models than chat models:

* Maximum image size: `10MiB`
* Maximum number of images: No limit
* Supported image file types: `jpg/jpeg` or `png`.
* Any image/text input order is accepted (e.g. text prompt can precede image prompt)

## Parameters

## Constructing the Message Body - Difference from Chat

The request message to image understanding is similar to chat. The main difference is that instead of text input:

```json
[
    {
        "role": "user",
        "content": "What is in this image ?",
    }
]
```

We send in `content` as a list of objects:

```json
[
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": "data:image/jpeg;base64,<base64_image_string>",
                    "detail": "high",
                },
            },
            {
                "type": "text",
                "text": "What is in this image ?",
            },
        ],
    }
]
```

The `image_url.url` can also be the image's url on the Internet.

You can use the text prompt to ask questions about the image(s), or discuss topics with the image as context to the discussion, etc.

## Web URL input

The model supports web URL as inputs for images. The API will fetch the image from the public URL and handle it as part of the chat. Integrating with URLs is as simple as:

```python
import os
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
image_url = (
    "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png"
)

client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": image_url,
                    "detail": "high",
                },
            },
            {
                "type": "text",
                "text": "What's in this image?",
            },
        ],
    },
]

completion = client.chat.completions.create(
    model="grok-2-vision-latest",
    messages=messages,
    temperature=0.01,
)

print(completion.choices[0].message.content)
```

```javascript
import OpenAI from "openai";
const openai = new OpenAI({
    apiKey: process.env.XAI_API_KEY,
    baseURL: "https://api.x.ai/v1",
});
const image_url =
    "https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png";

const completion = await openai.chat.completions.create({
    model: "grok-2-vision-latest",
    messages: [
        {
            role: "user",
            content: [
                {
                    type: "image_url",
                    image_url: {
                        url: image_url,
                        detail: "high",
                    },
                },
                {
                    type: "text",
                    text: "What's in this image?",
                },
            ],
        },
    ],
});

console.log(completion.choices[0].message.content);
```

## Base64 string input

You will need to pass in base64 encoded image directly in the request, in the user messages.

Here is an example of how you can load a local image, encode it in Base64 and use it as part of your conversation:

```python
import os
from openai import OpenAI
import os
import base64

XAI_API_KEY = os.getenv("XAI_API_KEY")
image_path = "..."

client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode("utf-8")
    return encoded_string

# Getting the base64 string
base64_image = encode_image(image_path)

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}",
                    "detail": "high",
                },
            },
            {
                "type": "text",
                "text": "What's in this image?",
            },
        ],
    },
]

completion = client.chat.completions.create(
    model="grok-2-vision-latest",
    messages=messages,
    temperature=0.01,
)

print(completion.choices[0].message.content)
```

```javascript
import { promises as fs } from "fs";
import OpenAI from "openai";

const openai = new OpenAI({
    apiKey: process.env.XAI_API_KEY,
    baseURL: "https://api.x.ai/v1",
});
const image_path =
    "...";

async function getBase64(filePath) {
    try {
        const buffer = await fs.readFile(filePath);
        let base64 = buffer.toString("base64");
        while (base64.length % 4 > 0) {
            base64 += "=";
        }
        return base64;
    } catch (error) {
        throw error;
    }
}

const base64_image = await getBase64(image_path);

const completion = await openai.chat.completions.create({
    model: "grok-2-vision-latest",
    messages: [
        {
            role: "user",
            content: [
                {
                    type: "image_url",
                    image_url: {
                        url: \`data:image/jpeg;base64,$\{base64_image\}\`,
                        detail: "high",
                    },
                },
                {
                    type: "text",
                    text: "What's in this image?",
                },
            ],
        },
    ],
});

console.log(completion.choices[0].message.content);
```

## Multiple images input

You can send multiple images in the prompt, for example:

```python
messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image1}",
                    "detail": "high"
                }
            },
            {
                "type": "text",
                "text": "What are in these images?"
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image2}",
                    "detail": "high",
                }
            }
        ],
    },
]
```

```javascript
messages: [
        {
            role: "user",
            content: [
                {
                    type: "image_url",
                    image_url: {
                        url: \`data:image/jpeg;base64,$\{base64_image1\}\`,
                        detail: "high",
                    },
                },
                {
                    type: "text",
                    text: "What are in these images?",
                },
                {
                    type: "image_url",
                    image_url: {
                        url: \`data:image/jpeg;base64,$\{base64_image2\}\`,
                        detail: "high",
                    },
                },
            ]
        }
    ],
```

The image prompts can interleave with text prompts in any order.

## Image token usage

The prompt image token usage is provided in the API response. Each image will be automatically broken down into tiles of 448x448 pixels, and each tile will consume 256 tokens. The final generation will include an extra tile, so each image would consume `(# of tiles + 1) * 256` tokens. There is a maximum limit of 6 tiles, so your input would consume less than 1,792 tokens per image.

```python
# Stream response
print(next(stream).usage.prompt_tokens_details.image_tokens)

# Non-stream response
print(response.usage.prompt_tokens_details.image_tokens)
```


===/docs/guides/live-search===
#### Guides

# Live Search

The chat completion endpoint supports querying data and considering those in generating responses. With this
functionality, instead of orchestrating web search and LLM tool calls yourself, you can get chat responses considering
web, news and X search results directly from the API.

Live search is available via the chat completions endpoint. It is turned off by default.

Customers are in control of the content they receive including disabling safesearch. The safesearch is on by default.

For more details, refer to `search_parameters` in [API Reference - Chat completions](../api-reference#chat-completions).

## Enabling Search

To enable search, you need to specify in your chat completions request an additional field
`search_parameters`, with `"mode"` from one of `"auto"`, `"on"`.

The `"mode"` field sets the preference of data source:

* `"off"` (default): Disables search and uses the model without accessing additional information from data sources.
* `"auto"`: Data is available to the model, but let the model decide whether to search and which
  data source to use.
* `"on"`: Enable search, let the model decide which datasource to use within the provided data sources.
  For example, you can send the following request, where the model will decide whether to search in data:

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
      "messages": [
        {
          "role": "user",
          "content": "Provide me a digest of world news in the last 24 hours."
        }
      ],
      "search_parameters": {
        "mode": "auto"
      },
     "model": "grok-3-latest"
     }'
```

## Returning citations

You might want to return to the data source yourself after receiving the inference result. To return the
data source citation in the response, you can set `"return_citations": true`.

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
      "messages": [
        {
          "role": "user",
          "content": "Provide me a digest of world news in the last 24 hours."
        }
      ],
      "search_parameters": {
        "mode": "auto",
        "return_citations": true
      },
      "model": "grok-3-latest"
      }'
```

### Streaming behavior with citations

During streaming, you would get the chat response chunks as usual. The citations will be returned as a list of url
strings in the field `"citations"` only in the last chunk. This is similar to how the usage data is returned with
streaming.

## Set date range of the search data

You can restrict the date range of search data used by specifying `"from_date"` and `"to_date"`. This limits the
data to the period from `"from_date"` to `"to_date"`, including both dates.

Both fields need to be in ISO8601 format, e.g. "YYYY-MM-DD".

The fields can also be independently used. With only `"from_date"` specified, the data used will be from the
`"from_date"` to today, and with only `"to_date"` specified, the data used will be all data till the `"to_date"`.

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
      "messages": [
        {
          "role": "user",
          "content": "What is the most viral meme in 2022?"
        }
      ],
      "search_parameters": {
        "mode": "auto",
        "from_date": "2022-01-01",
        "to_date": "2022-12-31"
      },
      "model": "grok-3-latest"
      }'
```

## Limit the maximum amount of data sources

You can set a limit on how many data sources will be considered in the query via `"max_search_results"`.
The default limit is 20.

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
      "messages": [
        {
          "role": "user",
          "content": "Can you recommend the top 10 burger place in London?"
        }
      ],
      "search_parameters": {
        "mode": "auto",
        "max_search_results": 10
      },
      "model": "grok-3-latest"
      }'
```

## Data sources and parameters

In `"sources`" of `"search_parameters"`, you can add a list of sources to be potentially used in search. Each source is
an object with source name and parameters for that source, with the name of the source in the `"type"` field.

If nothing is specified, the sources to be used will default to `"web"` and `"x"`.

For example, the following enables web, X search and news:

```json
"sources": [
            {"type": "web"},
            {"type": "x"},
            {"type": "news"}
]
```

### Data Source Parameters - Web

Use `"excluded_websites"` in `"sources": [{"type": "web"}]` to exclude websites from the query.

You can disable safesearch via `"sources": [{"type": "web", "safe_search": false }]`. The safesearch is on by default.

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
      "messages": [
        {
          "role": "user",
          "content": "What are some recently discovered alternative DNA shapes?"
        }
      ],
      "search_parameters": {
        "mode": "auto",
        "sources": [
          {"type": "web", "excluded_websites": ["wikipedia.org"]}
        ]
      },
      "model": "grok-3-latest"
      }'
```

### Data Source Parameters - X

Use `"x_handles"` in `"sources": [{"type": "x"}]` to consider X posts only from a given list of X handles.

You can disable safesearch via `"sources": [{"type": "x", "safe_search": false }]`. The safesearch is on by default.

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
      "messages": [
        {
          "role": "user",
          "content": "What are the latest updates on Grok?"
        }
      ],
      "search_parameters": {
        "mode": "auto",
        "sources": [
          {"type": "x", "x_handles": ["grok"]}
        ]
      },
      "model": "grok-3-latest"
      }'
```

### Limit query data to be from a specific country/region

Sometimes you might want to include data from a specific country/region. To do so, you can add an ISO alpha-2 code of
the country to `"country"` in `"web"` or `"news"` of the `"sources"`.

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
      "messages": [
      {
        "role": "user",
        "content": "Where is the best place to go skiing this year?"
      }
      ],
      "search_parameters": {
        "mode": "auto",
        "sources": [
        {"type": "web", "country": "CH"}
        ],
      },
      "model": "grok-3-latest"
      }'
```


===/docs/guides/migration===
#### Guides

# Migration from Other Providers

Some of Grok users might have migrated from other LLM providers. xAI API is designed to be compatible with both OpenAI and Anthropic SDKs, except certain capabilities not offered by respective SDK.
If you can use either SDKs, we recommend using OpenAI SDK for better stability.

In two steps:

1. At API client object construction, you need to set the "base url" to `https://api.x.ai/v1` and "API key" to your xAI API key (obtained from [xAI Console](https://console.x.ai)).
2. When sending message for inference, set "model" to be one of the Grok [model](../models) names.

If you use third-party tools such as LangChain ([JavaScript](https://js.langchain.com/docs/integrations/chat/xai/)/[Python](https://python.langchain.com/docs/integrations/providers/xai/)) and [Continue](https://docs.continue.dev/customize/model-providers/xai),
they usually have a common base class for LLM providers. You only need to change the provider and API keys. You can refer to their documentations for case-by-case instrcutions.

Examples using OpenAI and Anthropic SDKs:

**OpenAI SDK**

```python
from openai import OpenAI

client = OpenAI(
api_key=XAI_API_KEY,
base_url="https://api.x.ai/v1",
)

# ...

completion = client.chat.completions.create(
model="grok-3-latest",

# ...
```

```javascript
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: $XAI_API_KEY,
  baseURL: "https://api.x.ai/v1",
});

// ...

const completion = await openai.chat.completions.create({
  model: "grok-3-latest",
// ...
```

**Anthropic SDK**

```python
from anthropic import Anthropic
    
client = Anthropic(
  api_key=XAI_API_KEY,
  base_url="https://api.x.ai",
)

# ...

message = client.messages.create(
model="grok-3-latest",

# ...
```

```javascript
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic({
  apiKey: $XAI_API_KEY,
  baseURL: "https://api.x.ai/",
});

// ...

const msg = await anthropic.messages.create({
  model: "grok-3-latest",
// ...
```


===/docs/guides/reasoning===
#### Guides

# Reasoning

Grok 3 Mini is a lightweight, smaller thinking model. Unlike traditional models that generate answers immediately, Grok 3 Mini thinks before responding. Itâ€™s ideal for reasoning-heavy tasks that donâ€™t demand extensive domain knowledge, and shines in math-specific and quantitative use cases, such as solving challenging puzzles or math problems.

Reasoning is only supported by `grok-3-mini` and `grok-3-mini-fast`.The Grok 3 models `grok-3` and `grok-3-fast` do not support reasoning.

## Key Features

* **Think Before Responding**: Thinks through problems step-by-step before delivering an answer.
* **Math & Quantitative Strength**: Excels at numerical challenges and logic puzzles.
* **Reasoning Trace**: The model's thoughts are available via the `reasoning_content` field in the response completion object (see example below).

You can access the model's raw thinking trace via the `message.reasoning_content` of the chat completion response.

## Control how hard the model thinks

The `reasoning_effort` parameter controls how much time the model spends thinking before responding. It must be set to one of these values:

* **`low`**: Minimal thinking time, using fewer tokens for quick responses.
* **`high`**: Maximum thinking time, leveraging more tokens for complex problems.

Choosing the right level depends on your task: use `low` for simple queries that should complete quickly, and `high` for harder problems where response latency is less important.

## Usage Example

Hereâ€™s a simple example using Grok 3 Mini to multiply 101 by 3. Notice that we can access both the reasoning content and final response.

```python
import os
from openai import OpenAI

messages = [
    {
        "role": "system",
        "content": "You are a highly intelligent AI assistant.",
    },
    {
        "role": "user",
        "content": "What is 101*3?",
    },
]

client = OpenAI(
    base_url="https://api.x.ai/v1",
    api_key=os.getenv("XAI_API_KEY"),
)

completion = client.chat.completions.create(
    model="grok-3-mini", # or "grok-3-mini-fast"
    reasoning_effort="high",
    messages=messages,
    temperature=0.7,
)

print("Reasoning Content:")
print(completion.choices[0].message.reasoning_content)

print("\\nFinal Response:")
print(completion.choices[0].message.content)

print("\\nNumber of completion tokens (input):")
print(completion.usage.completion_tokens)

print("\\nNumber of reasoning tokens (input):")
print(completion.usage.completion_tokens_details.reasoning_tokens)
```

```javascript
import OpenAI from "openai";

const client = new OpenAI({
    apiKey: "<api key>",
    baseURL: "https://api.x.ai/v1",
});

const completion = await client.chat.completions.create({
    model: "grok-3-mini",
    messages: [
      {
          "role": "system",
          "content": "You are a highly intelligent AI assistant.",
      },
      {
          "role": "user",
          "content": "What is 101*3?",
      },
    ],
});

console.log("Reasoning Content:", completion.choices[0].message.reasoning_content);

console.log("\\nFinal Response:", completion.choices[0].message.content);

console.log("\\nNumber of completion tokens (input):", completion.usage.completion_tokens);

console.log("\\nNumber of reasoning tokens (input):", completion.usage.completion_tokens_details.reasoning_tokens);
```

```bash
curl https://api.x.ai/v1/chat/completions \\
    -H "Content-Type: application/json" \\
    -H "Authorization: Bearer $XAI_API_KEY" \\
    -d '{
        "messages": [
            {
            "role": "system",
            "content": "You are a highly intelligent AI assistant."
            },
            {
            "role": "user",
            "content": "What is 101*3?"
            }
        ],
        "model": "grok-3-mini-latest",
        "stream": false,
        "temperature": 0.7,
        "reasoning_effort":"high"
    }'
```

### Sample Output

```
Reasoning Content:
Let me calculate 101 multiplied by 3:
101 * 3 = 303.
I can double-check that: 100 * 3 is 300, and 1 * 3 is 3, so 300 + 3 = 303. Yes, that's correct.

Final Response:
The result of 101 multiplied by 3 is 303.

Number of completion tokens (input):
14

Number of reasoning tokens (input):
310
```

## When to Use Reasoning

* **Use `grok-3-mini` or `grok-3-mini-fast`**: For tasks that can benefit from logical reasoning (such as meeting scheduling or math problems). Also great for tasks that don't require deep domain knowledge about a specific subject (eg basic customer support bot).
* **Use `grok-3` or `grok-3-fast`**: For queries requiring deep domain expertise or world knowledge (eg healthcare, legal, finance).

## Notes on Consumption

When you use a reasoning model, the reasoning tokens are also added to your final consumption amount. The reasoning token consumption will likely increase when you use a higher `reasoning_effort` setting.


===/docs/guides/streaming-response===
#### Guides

# Streaming Response

Streaming outputs is **supported by all models with text output capability** (Chat, Image Understanding, etc.). It is **not supported by models with image output capability** (Image Generation).

Streaming outputs uses [Server-Sent Events (SSE)](https://en.wikipedia.org/wiki/Server-sent_events) that let the server send back the delta of content in event streams.

Streaming responses are beneficial for providing real-time feedback, enhancing user interaction by allowing text to be displayed as it's generated.

To enable streaming, you must set `"stream": true` in your request:

```python
import os
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(
    api_key=XAI_API_KEY,
    base_url="https://api.x.ai/v1",
)

stream = client.chat.completions.create(
    model="grok-3-latest",
    messages=[
        {"role": "system", "content": "You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy."},
        {"role": "user", "content": "What is the meaning of life, the universe, and everything?"},
    ],
    stream=True  # Set streaming here
)

for chunk in stream:
    print(chunk.choices[0].delta.content, end="", flush=True)
```

```javascript
import OpenAI from "openai";
const openai = new OpenAI({
  apiKey: "<api key>",
  baseURL: "https://api.x.ai/v1",
});

const stream = await openai.chat.completions.create({
  model: "grok-3-latest",
  messages: [
    { role: "system", content: "You are Grok, a chatbot inspired by the Hitchhiker's Guide to the Galaxy." },
    {
      role: "user",
      content: "What is the meaning of life, the universe, and everything?",
    }
  ],
  stream: true
});

for await (const chunk of stream) {
    console.log(chunk.choices[0].delta.content);
}
```

```bash
curl https://api.x.ai/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer $XAI_API_KEY" \\
  -d '{
        "messages": [
          {
            "role": "system",
            "content": "You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy."
          },
          {
            "role": "user",
            "content": "What is the meaning of life, the universe, and everything?"
          }
        ],
        "model": "grok-3-latest",
        "stream": true,
        "temperature": 0
      }'
```

You'll get the event streams like these:

```bash
data: {
"id":"<completion_id>","object":"chat.completion.chunk","created":<creation_time>,
"model":"grok-3",
"choices":[{"index":0,"delta":{"content":"Ah","role":"assistant"}}],
"usage":{"prompt_tokens":41,"completion_tokens":1,"total_tokens":42,
"prompt_tokens_details":{"text_tokens":41,"audio_tokens":0,"image_tokens":0,"cached_tokens":0}},
"system_fingerprint":"fp_xxxxxxxxxx"}

data: {
"id":"<completion_id>","object":"chat.completion.chunk","created":<creation_time>,
"model":"grok-3",
"choices":[{"index":0,"delta":{"content":",","role":"assistant"}}],
"usage":{"prompt_tokens":41,"completion_tokens":2,"total_tokens":43,
"prompt_tokens_details":{"text_tokens":41,"audio_tokens":0,"image_tokens":0,"cached_tokens":0}},
"system_fingerprint":"fp_xxxxxxxxxx"
}

data: [DONE]
```

It is recommended that you use a client SDK to parse the event stream.

Example streaming responses in Python/Javascript:

```bash
Ah, the ultimate question! According to Douglas Adams, the answer is **42**. However, the trick lies in figuring out what the actual question is. If you're looking for a bit more context or a different perspective:

- **Philosophically**: The meaning of life might be to seek purpose, happiness, or to fulfill one's potential.
- **Biologically**: It could be about survival, reproduction, and passing on genes.
- **Existentially**: You create your own meaning through your experiences and choices.

But let's not forget, the journey to find this meaning might just be as important as the answer itself! Keep exploring, questioning, and enjoying the ride through the universe. And remember, don't panic!
```


===/docs/guides/structured-outputs===
#### Guides

# Structured Outputs

Structured Outputs is a feature that lets the API return responses in a specific, organized format, like JSON or other schemas you define. Instead of getting free-form text, you receive data that's consistent and easy to parse.

Ideal for tasks like document parsing, entity extraction, or report generation, it lets you define schemas using tools like
[Pydantic](https://pydantic.dev/) or [Zod](https://zod.dev/) to enforce data types, constraints, and structure.

When using structured outputs, the LLM's response is **guaranteed** to match your input schema.

## Supported models

Structured outputs is supported for the following models:

* `grok-3`
* `grok-3-fast`
* `grok-3-mini`
* `grok-3-mini-fast`
* `grok-2-vision-1212`
* `grok-2-1212` (deprecated)

## Example: Invoice Parsing

A common use case for Structured Outputs is parsing raw documents. For example, invoices contain structured data like vendor details, amounts, and dates, but extracting this data from raw text can be error-prone. Structured Outputs ensure the extracted data matches a predefined schema.

Let's say you want to extract the following data from an invoice:

* Vendor name and address
* Invoice number and date
* Line items (description, quantity, price)
* Total amount and currency

We'll use structured outputs to have Grok generate a strongly-typed JSON for this.

### Step 1: Defining the Schema

You can use [Pydantic](https://pydantic.dev/) or [Zod](https://zod.dev/) to define your schema.

```python
from pydantic import BaseModel, Field
from datetime import date
from enum import Enum
from typing import List

class Currency(str, Enum):
    USD = "USD"
    EUR = "EUR"
    GBP = "GBP"

class LineItem(BaseModel):
    description: str = Field(description="Description of the item or service")
    quantity: int = Field(description="Number of units", ge=1)
    unit_price: float = Field(description="Price per unit", ge=0)

class Address(BaseModel):
    street: str = Field(description="Street address")
    city: str = Field(description="City")
    postal_code: str = Field(description="Postal/ZIP code")
    country: str = Field(description="Country")

class Invoice(BaseModel):
    vendor_name: str = Field(description="Name of the vendor")
    vendor_address: Address = Field(description="Vendor's address")
    invoice_number: str = Field(description="Unique invoice identifier")
    invoice_date: date = Field(description="Date the invoice was issued")
    line_items: List[LineItem] = Field(description="List of purchased items/services")
    total_amount: float = Field(description="Total amount due", ge=0)
    currency: Currency = Field(description="Currency of the invoice")
```

```javascript
import { z } from "zod";

const CurrencyEnum = z.enum(["USD", "EUR", "GBP"]);

const LineItemSchema = z.object({
  description: z.string().describe("Description of the item or service"),
  quantity: z.number().int().min(1).describe("Number of units"),
  unit_price: z.number().min(0).describe("Price per unit"),
});

const AddressSchema = z.object({
  street: z.string().describe("Street address"),
  city: z.string().describe("City"),
  postal_code: z.string().describe("Postal/ZIP code"),
  country: z.string().describe("Country"),
});

const InvoiceSchema = z.object({
  vendor_name: z.string().describe("Name of the vendor"),
  vendor_address: AddressSchema.describe("Vendor's address"),
  invoice_number: z.string().describe("Unique invoice identifier"),
  invoice_date: z.string().date().describe("Date the invoice was issued"),
  line_items: z.array(LineItemSchema).describe("List of purchased items/services"),
  total_amount: z.number().min(0).describe("Total amount due"),
  currency: CurrencyEnum.describe("Currency of the invoice"),
});
```

### Step 2: Prepare The Prompts

### System Prompt

The system prompt instructs the model to extract invoice data from text. Since the schema is defined separately, the prompt can focus on the task without explicitly specifying the required fields in the output JSON.

```text
Given a raw invoice, carefully analyze the text and extract the relevant invoice data into JSON format.
```

### Example Invoice Text

```text
Vendor: Acme Corp, 123 Main St, Springfield, IL 62704
Invoice Number: INV-2025-001
Date: 2025-02-10
Items:
- Widget A, 5 units, $10.00 each
- Widget B, 2 units, $15.00 each
Total: $80.00 USD
```

### Step 3: The Final Code

Use the structured outputs feature of the the SDK to parse the invoice.

```python
from openai import OpenAI

from pydantic import BaseModel, Field
from datetime import date
from enum import Enum
from typing import List

# Pydantic Schemas
class Currency(str, Enum):
    USD = "USD"
    EUR = "EUR"
    GBP = "GBP"

class LineItem(BaseModel):
    description: str = Field(description="Description of the item or service")
    quantity: int = Field(description="Number of units", ge=1)
    unit_price: float = Field(description="Price per unit", ge=0)

class Address(BaseModel):
    street: str = Field(description="Street address")
    city: str = Field(description="City")
    postal_code: str = Field(description="Postal/ZIP code")
    country: str = Field(description="Country")

class Invoice(BaseModel):
    vendor_name: str = Field(description="Name of the vendor")
    vendor_address: Address = Field(description="Vendor's address")
    invoice_number: str = Field(description="Unique invoice identifier")
    invoice_date: date = Field(description="Date the invoice was issued")
    line_items: List[LineItem] = Field(description="List of purchased items/services")
    total_amount: float = Field(description="Total amount due", ge=0)
    currency: Currency = Field(description="Currency of the invoice")

client = OpenAI(
    api_key="<YOUR_XAI_API_KEY_HERE>",
    base_url="https://api.x.ai/v1",
)

completion = client.beta.chat.completions.parse(
    model="grok-3",
    messages=[
        {"role": "system", "content": "Given a raw invoice, carefully analyze the text and extract the invoice data into JSON format."},
        {"role": "user", "content": """
            Vendor: Acme Corp, 123 Main St, Springfield, IL 62704
            Invoice Number: INV-2025-001
            Date: 2025-02-10
            Items:
            - Widget A, 5 units, $10.00 each
            - Widget B, 2 units, $15.00 each
            Total: $80.00 USD
        """}
    ],
    response_format=Invoice,
)

invoice = completion.choices[0].message.parsed
print(invoice)
```

```javascript
import OpenAI from "openai";
import { zodResponseFormat } from "openai/helpers/zod";
import { z } from "zod";

const CurrencyEnum = z.enum(["USD", "EUR", "GBP"]);

const LineItemSchema = z.object({
  description: z.string().describe("Description of the item or service"),
  quantity: z.number().int().min(1).describe("Number of units"),
  unit_price: z.number().min(0).describe("Price per unit"),
});

const AddressSchema = z.object({
  street: z.string().describe("Street address"),
  city: z.string().describe("City"),
  postal_code: z.string().describe("Postal/ZIP code"),
  country: z.string().describe("Country"),
});

const InvoiceSchema = z.object({
  vendor_name: z.string().describe("Name of the vendor"),
  vendor_address: AddressSchema.describe("Vendor's address"),
  invoice_number: z.string().describe("Unique invoice identifier"),
  invoice_date: z.string().date().describe("Date the invoice was issued"),
  line_items: z.array(LineItemSchema).describe("List of purchased items/services"),
  total_amount: z.number().min(0).describe("Total amount due"),
  currency: CurrencyEnum.describe("Currency of the invoice"),
});

const client = new OpenAI({
  apiKey: "<api key>",
  baseURL: "https://api.x.ai/v1",
});

const completion = await client.beta.chat.completions.parse({
  model: "grok-3-latest",
  messages: [
    { role: "system", content: "Given a raw invoice, carefully analyze the text and extract the invoice data into JSON format." },
    { role: "user", content: \`
      Vendor: Acme Corp, 123 Main St, Springfield, IL 62704
      Invoice Number: INV-2025-001
      Date: 2025-02-10
      Items:
      - Widget A, 5 units, $10.00 each
      - Widget B, 2 units, $15.00 each
      Total: $80.00 USD
    \` },
  ],
  response_format: zodResponseFormat(InvoiceSchema, "invoice"),
});

const invoice = completion.choices[0].message.parsed;
console.log(invoice);
```

### Step 4: Type-safe Output

The output will **always** be type-safe and respect the input schema.

```json
{
  "vendor_name": "Acme Corp",
  "vendor_address": {
    "street": "123 Main St",
    "city": "Springfield",
    "postal_code": "62704",
    "country": "IL"
  },
  "invoice_number": "INV-2025-001",
  "invoice_date": "2025-02-10",
  "line_items": [
    {"description": "Widget A", "quantity": 5, "unit_price": 10.0},
    {"description": "Widget B", "quantity": 2, "unit_price": 15.0}
  ],
  "total_amount": 80.0,
  "currency": "USD"
}
```


===/docs/key-information/billing===
#### Key Information

# Billing

**Ensure you are in the desired team before you change billing information**. When you save the billing information or making a purchase for the first time, the billing information is save to the team you are in and shared with its members.

There are two ways of billing:

* **Prepaid credits:** You can pre-purchase credits for your team. Your API consumption will be deducted from remaining prepaid credits available.
* **Monthly invoiced billing:** xAI will generate a monthly invoice based on your API consumption, when you don't have available prepaid credits. xAI will charge your default payment method with the invoiced amount at the end of each month.

**Monthly invoiced billing is disabled by default, with default Invoiced Spending Limit of $0.** This will introduce service disruption when you have consumed all of your prepaid credits. To enable monthly invoiced billing, set a higher than $0 Invoiced Spending Limit at [Billing -> Credits](https://console.x.ai/team/default/billing/credits) on xAI Console.

Your API consumption will be accounted for in the following order:

* Free/Promotional credits
* Prepaid credits
* Monthly invoiced billing (if Invoiced Spending Limit > $0)

**Any prepaid credits and added payment method will be made available to the team you made the purchase in.**

## Prepaid credits

This is the most common way to build with xAI API. Before using API, you purchase a given amount of credits. When you use the API, xAI will track your consumption and deduct the amount from the credits available in your account.

You can add prepaid credits on the xAI Console [Billing -> Credits](https://console.x.ai/team/default/billing/credits) page.

On the same page, you can view the remaining prepaid credits, enter promo code, as well as any free credits granted by xAI team.

Note: When you make the purchase via bank transfer instead of credit card, the payment will take 2-3 business days to process. You will be granted with credits after the process has completed.

## Monthly invoiced billing and invoiced billing limit

Enterprise customers might find it beneficial to enroll in monthly invoiced billing to avoid disruption to their services.

When you have set a **$0 invoiced billing limit** (default), xAI will only use your available prepaid credits. **Your API requests will be automatically rejected once your prepaid credits are depleted.**

If you want to use monthly billing, you can **increase your invoiced billing limit** on [Billing -> Credits](https://console.x.ai/team/default/billing/credits) page. xAI will attepmt to use your prepaid credits first, and the remaining amount will be charged to your default payment method at the end of the month. This ensures you won't experience interruption in consuming the API.

Once your monthly invoiced billing amount has reached the invoiced billing limit, you won't be able to get response until you have raised the invoiced billing limit.

## Saving payment method

When you make a purchase, we automatically keep it on file to make your next purchase easier. You can also manually add payment method on xAI Console [Billing page](https://console.x.ai/team/default/billing/payment) -> "Payment".

Currently we don't allow user to remove the last payment method on file. There might be changes in the future.

## Invoices

You can view your invoices for prepaid credits and monthly invoices on [Billing -> Invoices](https://console.x.ai/team/default/billing/invoices).

## Billing address and tax information

Your billing address and tax information will be displayed on the invoice. On [Billing -> Payment](https://console.x.ai/team/default/billing/payment), you can also add/change your billing address. When you add/change billing address, you can optionally add your organization's tax information.


===/docs/key-information/consumption-and-rate-limits===
#### Key Information

# Consumption and Rate Limits

Each `grok` model has different rate limits. To check your team's rate limits, you can visit [xAI Console Models Page](https://console.x.ai/team/default/models).

## Basic unit to calculate consumption â€” Tokens

Token is the base unit of prompt size for model inference and pricing purposes. It is consisted of one or more character(s)/symbol(s).

When a Grok model handles your request, an input prompt will be decomposed into a list of tokens through a tokenizer.
The model will then make inference based on the prompt tokens, and generate completion tokens.
After the inference is completed, the completion tokens will be aggregated into a completion response sent back to you.

Our system will add additional formatting tokens to the input/output token, and if you selected a reasoning model, additional reasoning tokens will be added into the total token consumption as well.
Your actual consumption would be reflected either in the `usage` object returned in the API response, or in Usage Explorer on the [xAI Console](https://console.x.ai).

You can use [Tokenizer](https://console.x.ai/team/default/tokenizer) on xAI Console to visualize tokens a given text prompt, or use [Tokenize text](../api-reference#tokenize-text) endpoint on the API.

### Text tokens

Tokens can be either of a whole word, or smaller chunks of character combinations. The more common a word is, the more likely it would be a whole token.

For example, Flint is broken down into two tokens, while Michigan is a whole token.

In another example, most words are tokens by themselves, but "drafter" is broken down into "dra" and "fter", and "postmaster" is broken down into "post" and "master".

For a given text/image/etc. prompt or completion sequence, different tokenizers may break it down into different lengths of lists.

Different Grok models may also share or use different tokenizers. Therefore, **the same prompt/completion sequence may not have the same amount of tokens across different models.**

The token count in a prompt/completion sequence should be approximately linear to the sequence length.

### Image prompt tokens

Each image prompt will take between 256 to 1792 tokens, depending on the size of the image. The image + text token count must be less than the overall context window of the model.

### Estimating consumption with tokenizer on xAI Console or through API

The tokenizer page or API might display less token count than the actual token consumption. The inference endpoints would automatically add pre-defined tokens to help our system process the request.

On xAI Console, you can use the [tokenizer page](https://console.x.ai/team/default/tokenizer) to estimate how many tokens your text prompt will consume. For example, the following message would consume 5 tokens (the actual consumption may vary because of additional special tokens added by the system).

Message body:

```json
[
    {
        role: "user",
        content:
            "How is the weather today?"
    }
]
```

Tokenize result on Tokenizer page:

You can also utilize the [Tokenize Text](api-reference#tokenize-text) API endpoint to tokenize the text, and count the output token array length.

## Hitting rate limits

To request a higher rate limit, please email support@x.ai with your anticipated volume.

For each tier, there is a maximum amount of requests per minute. This is to ensure fair usage by all users of the system.

Once your request frequency has reached the rate limit, you will receive error code `429` in response.

You can either:

* Upgrade your team to higher tiers
* Change your consumption pattern to send less requests

## Checking token consumption

In each completion response, there is a `usage` object detailing your prompt and completion token count. You might find it helpful to keep track of it, in order to avoid hitting rate limits or having cost surprises.

```json
"usage": {
  "prompt_tokens": 41,
  "completion_tokens": 87,
  "total_tokens": 128,
  "prompt_tokens_details": {
    "text_tokens": 41,
    "audio_tokens": 0,
    "image_tokens": 0,
    "cached_tokens": 0
  }
}
```

You can also check with OpenAI or Anthropic SDKs.
OpenAI SDK:

```python
import os
from openai import OpenAI

XAI_API_KEY = os.getenv("XAI_API_KEY")
client = OpenAI(base_url="https://api.x.ai/v1", api_key=XAI_API_KEY)

completion = client.chat.completions.create(
    model="grok-3-latest",
    messages=[
        {
            "role": "system",
            "content": "You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy.",
        },
        {
            "role": "user",
            "content": "What is the meaning of life, the universe, and everything?",
        },
    ],
)

if completion.usage:
    print(completion.usage.to_json())
```

```javascript
import OpenAI from "openai";
const openai = new OpenAI({
    apiKey: "<api key>",
    baseURL: "https://api.x.ai/v1",
});

const completion = await openai.chat.completions.create({
    model: "grok-3-latest",
    messages: [
        {
            role: "system",
            content:
                "You are Grok, a chatbot inspired by the Hitchhiker's Guide to the Galaxy.",
        },
        {
            role: "user",
            content:
                "What is the meaning of life, the universe, and everything?",
        },
    ],
});

console.log(completion.usage);
```


===/docs/key-information/migrating-to-new-models===
#### Key Information

# Migrating to New Models

As we release newer, more advanced models, we are focusing resources on supporting customers with these models and will
be phasing out older versions.

You will see `deprecated` tag by the deprecated model names on [xAI Console](https://console.x.ai) models page. You
should consider moving to a newer model when the model of your choice is being deprecated.

## Moving from an older generation model

When you move from an older model generation to a newer one, you usually won't need to make significant changes to
how you use the API. In your request body, you can switch the `"model"` field from the deprecating model to a current
model on [xAI Console](https://console.x.ai) models page.

The newer models are more performant, but you might want to check if your prompts and other parameters can work with the
new model and modify if necessary.

## Moving to the latest endpoints

When you are setting up to use new models, it might also be a good idea to ensure you're using the latest endpoints. The
latest endpoints have more stable supports for the model functionalities. Endpoints that are marked with `legacy`
might not receive any updates that support newer functionalities.

In general, the following endpoints are recommended:

* Text and image input and text output: [Chat Completions](../api-reference#chat-completions) - `/v1/chat/completions`
* Text input and image output: [Image Generations](../api-reference#image-generations) - `/v1/image/generations`
* Tokenization: [Tokenize Text](../api-reference#tokenize-text) - `/v1/tokenize-text`


===/docs/key-information/models===
#### Key Information

# Models and Pricing

An overview of our models' capabilities and their associated pricing. Our Grok 3 models come in two variants: a fast and a standard version ().

## What is the difference between grok-3 and grok-3-fast?

Both `grok-3` and `grok-3-fast` use the exact same underlying model and deliver identical response quality. The difference lies in how theyâ€™re served: `grok-3-fast` is served on faster infrastructure, offering response times that are significantly faster than the standard `grok-3`. The increased speed comes at a higher cost per output token.

`grok-3` and `grok-3-fast` point to the same underlying model. Choose `grok-3-fast` for latency-sensitive applications, and choose `grok-3` for reduced cost.

The same can be said for `grok-3-mini` and `grok-3-mini-fast`. Under the hood, both are identical models that differ only in response latency.

## Additional Information Regarding Models

The knowledge cutoff date for the Grok 3 model family is November 17, 2024.

* **No access to realtime events**
  * Unlike [grok.com](https://grok.com/) and [Grok in X](http://grok.x.com/), the Grok models on the xAI API are not connected to the internet.
  * Grok has no knowledge of current events or data beyond what was present in its training data. Please pass any realtime data as context in your system prompt.
* **Chat models**
  * No role order limitation: You can mix `system`, `user`, or `assistant` roles in any sequence for your conversation context.
* **Image input models**
  * Maximum image size: `10MiB`
  * Maximum number of images: No limit
  * Supported image file types: `jpg/jpeg` or `png`.
  * Any image/text input order is accepted (e.g. text prompt can precede image prompt)

## Model Aliases

Some models have aliases to help user automatically migrate to the next version of the same model. In general:

* `<modelname>` is aliased to the latest stable version.
* `<modelname>-latest` is aliased to the latest version. This is suitable for users who want to access the latest features.
* `<modelname>-<date>` refers directly to a specific model release. This will not be updated and is for workflows that demand consistency.

For most users, the aliased `<modelname>` or `<modelname>-latest` are recommended, as you would receive the latest features automatically.

## Billing and Availability

Your model access might vary depending on various factors such as geographical location, account limitations, etc.

For how the **bills are charged**, visit [Billing](billing) for more information.

For the most up-to-date information on **your team's model availability**, visit [Models Page](https://console.x.ai/team/default/models) on xAI Console.

## Model Input and Output

Each model can have one or multiple input and output capabilities.
The input capabilities refer to which type(s) of prompt can the model accept in the request message body.
The output capabilities refer to which type(s) of completion will the model generate in the response message body.

This is a prompt example for models with `text` input capability:

```json
[
  {
    "role": "system",
    "content": "You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy."
  },
  {
    "role": "user",
    "content": "What is the meaning of life, the universe, and everything?"
  }
]
```

This is a prompt example for models with `text` and `image` input capabilities:

```json
[
  {
    "role": "user",
    "content": [
      {
        "type": "image_url",
        "image_url": {
          "url": "data:image/jpeg;base64,<base64_image_string>",
          "detail": "high"
        },
      },
      {
        "type": "text",
        "text": "Describe what's in this image."
      }
    ]
  }
]
```

This is a prompt example for models with `text` input and `image` output capabilities:

```json
// The entire request body
{
  "model": "grok-2-image-latest",
  "prompt": "A cat in a tree",
  "n": 4
}
```

## Context Window

The context window determines the maximum amount of token accepted by the model in the prompt.

For more information on how token is counted, visit [Consumption and Rate Limits](consumption-and-rate-limits).

If you are sending the entire conversation history in the prompt for use cases like chat assistant, the sum of all the prompts in your conversation history must be no greater than the context window.


===/docs/key-information/usage-explorer===
#### Key Information

# Usage Explorer

Sometimes as a team admin, you might want to monitor the API consumption, either to track spending, or to detect anomalies. xAI Console provides an easy-to-use [Usage Explorer](https://console.x.ai/team/default/usage) for team admins to track API usage across API keys, models, etc.

## Basic usage

[Usage Explorer](https://console.x.ai/team/default/usage) page provides intuitive dropdown menus for you to customize how you want to view the consumptions.

For example, you can view your daily credit consumption with `Granularity: Daily`:

By default, the usage is calculated by cost in US Dollar. You can select Dimension -> Tokens or Dimension -> Billing items to change the dimension to token count or billing item count.

You can also see the usage with grouping. This way, you can easily compare the consumption across groups. In this case, we are trying to compare consumptions across test and production API keys, so we select `Group by: API Key`:

## Filters

The basic usage should suffice if you are only viewing general information. However, you can also use filters to conditionally display information.

The filters dropdown gives you the options to filter by a particular API key, a model, a request IP, a cluster, or the token type.


===/docs/resources/community-integrations===
#### Resources

# Community Integrations

Grok is also accessible via your favorite community integrations, enabling you to connect Grok to other parts of your system easily.

## Third-party SDK/frameworks

### LiteLLM

LiteLLM provides a simple SDK or proxy server for calling different LLM providers. If you're using LiteLLM, integrating xAI as your provider is straightforwardâ€”just swap out the model name and API key to xAI's Grok model in your configuration.

For latest information and more examples, visit [LiteLLM xAI Provider Documentation](https://docs.litellm.ai/docs/providers/xai).

As a quick start, you can use LiteLLM in the following fashion:

```python
from litellm import completion
import os

os.environ['XAI_API_KEY'] = ""
response = completion(
    model="xai/grok-3-latest",
    messages=[
        {
            "role": "user",
            "content": "What's the weather like in Boston today in Fahrenheit?",
        }
    ],
    max_tokens=10,
    response_format={ "type": "json_object" },
    seed=123,
    stop=["\n\n"],
    temperature=0.2,
    top_p=0.9,
    tool_choice="auto",
    tools=[],
    user="user",
)
print(response)
```

### Vercel AI SDK

[Vercel's AI SDK](https://sdk.vercel.ai/) supports a [xAI Grok Provider](https://sdk.vercel.ai/providers/ai-sdk-providers/xai) for integrating with xAI API.

By default it uses your xAI API key in `XAI_API_KEY` variable.

To generate text use the `generateText` function:

```javascript
import { xai } from '@ai-sdk/xai';
import { generateText } from 'ai';

const { text } = await generateText({
  model: xai('grok-3-latest'),
  prompt: 'Write a vegetarian lasagna recipe for 4 people.',
});
```

You can also customize the setup like the following:

```javascript
import { createXai } from '@ai-sdk/xai';

const xai = createXai({
  apiKey: 'your-api-key',
});
```

You can also generate images with the `generateImage` function:

```javascript
import { xai } from '@ai-sdk/xai';
import { experimental_generateImage as generateImage } from 'ai';

const { image } = await generateImage({
  model: xai.image('grok-2-image'),
  prompt: 'A cat in a tree',
});
```

## Coding assistants

### Continue

You can use Continue extension in VSCode or JetBrains with xAI's models.

To start using xAI models with Continue, you can add the following in Continue's config file `~/.continue/config.json`(MacOS and Linux)/`%USERPROFILE%\.continue\config.json`(Windows).

```json
 "models": [
   {
     "title": "Grok-3",
     "provider": "xAI",
     "model": "grok-3-latest",
     "apiKey": "[XAI_API_KEY]"
   }
 ]
```

Visit [Continue's Documentation](https://docs.continue.dev/chat/model-setup#grok-2-from-xai) for more details.


===/docs/resources/faq-api/accounts===
#### Resources / FAQ - xAI API

# Accounts

## How do I create an account for the API?

Carefully select your sign-up email. We cannot change your xAI account's email once you have signed-up.
You need to sign-up with a new email address and optionally delete the original account.

You can create an account at https://accounts.x.ai, or https://console.x.ai. To link your X account automatically to
your xAI account, choose to sign up with X account.

## If I already have an account for Grok, can I use the same account for API access?

Yes, the account is shared between Grok and xAI API. You can manage the sign-in details at https://accounts.x.ai.

However, the billing is separate for Grok and xAI API. You can manage your billing for xAI API on [xAI Console](https://console.x.ai).
To manage billing for Grok, visit https://grok.com -> Settings -> Billing, or directly with Apple/Google if you made the
purchase via Apple App Store or Google Play.

## How do I manage my account?

You can visit https://accounts.x.ai to manage your account.

Please note the xAI account is different from the X account, and xAI cannot assist you with X account issues. Please
contact X via [X Help Center](https://help.x.com/) or Premium Support if you encounters any issues with your X account.

## How do I delete my account?

We are sorry to see you go!

You can visit [xAI Accounts](https://accounts.x.ai/account) to delete your account. You can restore your account after log in again and confirming restoration within 30 days.


===/docs/resources/faq-api/billing===
#### Resources / FAQ - xAI Console

# Billing

## I'm having payment issues with an Indian payment card

Unfortunately we cannot process Indian payment cards for our API service. We are working toward supporting it but you might want to consider using third-party API in the mean time. As Grok Website and Apps' payments are handled differently, those are not being affected.

## When will I be charged?

* Prepaid Credits: If you choose to use prepaid credits, youâ€™ll be charged when you buy them. These credits will be assigned to the team you select during purchase.

* Monthly Invoiced Billing: If you set your [invoiced spending limit](billing#monthly-invoiced-billing-and-invoiced-billing-limit) above $0, any usage beyond your prepaid credits will be charged at the end of the month.

* API Usage: When you make API requests, the cost is calculated immediately. The amount is either deducted from your available prepaid credits or added to your monthly invoice if credits are exhausted.

If you change your [invoiced spending limit](billing#monthly-invoiced-billing-and-invoiced-billing-limit) to be greater than $0, you will be charged at the end of the month for any extra consumption after your prepaid credit on the team has run out.

Your API consumption will be calculated when making the requests, and the corresponding amount will be deducted from your remaining credits or added to your monthly invoice.

Check out [Billing](billing) for more information.

## Can prepaid API credits be refunded?

Unfortunately, we are not able to offer refunds on any prepaid credit purchase unless in regions required by law.

### My prompt token consumption from the API is different from the token count I get from xAI Console Tokenizer or tokenize text endpoint

The inference endpoints add pre-defined tokens to help us process the request. Therefore, these tokens would be added to the total prompt token consumption. For more information, see:
[Estimating consumption with tokenizer on xAI Console or Estimating consumption with tokenizer on xAI Console or through API](consumption-and-rate-limits#estimating-consumption-with-tokenizer-on-xai-console-or-through-api).


===/docs/resources/faq-api===
#### Resources

# FAQ - xAI Console

Frequently asked questions on using the [xAI Console](https://console.x.ai), including creating teams, managing roles, and configuring settings.

You can find details on the following topics:


===/docs/resources/faq-api/security===
#### Resources / FAQ - xAI API

# Security

## Does xAI train on customers' API requests?

xAI never trains on your API inputs or outputs without your explicit permission.

API requests and responses are temporarily stored on our servers for 30 days in case they need to be audited for potential abuse or misuse. This data is automatically deleted after 30 days.

## Is the xAI API HIPAA compliant?

To inquire about a Business Associate Agreement (BAA), please complete our [BAA Questionnaire](https://forms.gle/YAEdX3XUp6MvdEXW9). A member of our team will review your responses and reach out with next steps.

## Is xAI GDPR and SOC II compliant?

We are SOC 2 Type 1 compliant. Customers with a signed NDA can refer to our [Trust Center](https://trust.x.ai/) for up-to-date information on our certifications and data governance.

## Do you have Audit Logs?

Team admins are able to view an audit log of user interactions. This lists all of the user interactions with our API server. You can view it at [xAI Console -> Audit Log](https://console.x.ai/team/default/audit).

The admin can also search by Event ID, Description or User to filter the results shown. For example, this is to filter by description matching `ListApiKeys`:

You can also view the audit log across a range of dates with the time filter:

## How can I securely manage my API keys?

Treat your xAI API keys as sensitive information, like passwords or credit card details. Do not share keys between teammates to avoid unauthorized access. Store keys securely using environment variables or secret management tools. Avoid committing keys to public repositories or source code.

Rotate keys regularly for added security. If you suspect a compromise, log into the xAI console first. Ensure you are viewing the correct team, as API keys are tied to specific teams. Navigate to the "API Keys" section via the sidebar. In the API Keys table, click the vertical ellipsis (three dots) next to the key. Select "Disable key" to deactivate it temporarily or "Delete key" to remove it permanently. Then, click the "Create API Key" button to generate a new one and update your applications.

xAI partners with GitHub's Secret Scanning program to detect leaked keys. If a leak is found, we disable the key and notify you via email. Monitor your account for unusual activity to stay protected.

===/docs/resources/faq-api/team-management===
#### Resources / FAQ - xAI Console

# Team Management

## What are teams?

Teams are the level at which xAI tracks API usage, processes billing, and issues invoices.

* If youâ€™re the team creator and donâ€™t need a new team, you can rename your Personal Team and add members instead of creating a new one.
* Each team has **roles**:
  * **Admin**: Can modify team name, billing details, and manage members.
  * **Member**: Cannot make these changes.
  * The team creator is automatically an Admin.

## Which team am I on?

When you sign up for xAI, youâ€™re automatically assigned to a **Personal Team**, which you can view the top bar of [xAI Console](https://console.x.ai).

## How can I manage teams and team members?

### Create a Team

1. Click the dropdown menu in the xAI Console.
2. Select **+ Create Team**.

3) Follow the on-screen instructions. You can edit these details later.

### Rename or Describe a Team

Admins can update the team name and description on the [Settings page](https://console.x.ai/team/default/settings).

### Manage Team Members

Admins can add or remove members by email on the [Users page](https://console.x.ai/team/default/users).

* Assign members as **Admin** or **Member**.
* If a user is removed, their API keys remain with the team.

### Delete a Team

To permanently delete a team:

1. Go to the [Settings page](https://console.x.ai/team/default/settings).
2. Follow the instructions under **Delete Team**.\
   ![Delete Team](/assets/docs/resources/faq-console/delete-team.png)

Deleting a team removes its prepaid credits.

## How to automatically add users to team with my organization's email domain?

Admins can enable automatic team joining for users with a shared email domain:

1. Go to the [Settings page](https://console.x.ai/team/default/settings).
2. Add the domain under **Verified Domains**.\
   ![Add Domain](/assets/docs/resources/faq-console/add-domain.png)
3. Add a `domain-verification` key to your domainâ€™s DNS TXT record to verify ownership.

Users signing up with a verified domain email will automatically join the team.


===/docs/resources/faq-grok===
#### Resources

# FAQ - Grok Website / Apps

While the documentation is mainly meant for our API users, you can find some commonly asked questions here for our consumer-facing website/apps.

## How can I link my X account sign-in/subscription to my xAI account?

If you have an existing xAI account, **DO NOT** sign-up with X account if you want to add your X account as a sign-in method.

On [Grok Website](https://grok.com), go to Settings -> Account. Click on Connect your X Account button. This will take you to X's SSO page to add X account as a sign-in method for xAI.

xAI will be able to retrieve your X subscription status and grant relevant benefits after linking.

## How can I delete the account?

Your xAI account can be deleted by following the steps here: [How do I delete my account?](../faq#how-do-i-delete-my-account) If you are using the same account to access our API, your API access will be removed as well.

## How do I unsubscribe?

If you have subscribed to SuperGrok, you can email support@x.ai (purchased from Grok Website) or [Request a refund for app](https://support.apple.com/118223) (purchased from Apple App Store).

If you have subscribed to X Premium, X (not xAI) would be responsible for processing refund where required by law. You can [submit a refund request from X](https://help.x.com/forms/x-refund-request). See more details regarding X Premium subscriptions on [X Help Center](https://help.x.com/using-x/x-premium).


